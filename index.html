<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Reasoning LLMs Are Just Efficient Samplers:
        RL Training Elicits No Transcending Capacity"> 
  <meta name="keywords" content="Qwen, Deepseek-R1, PPO, GRPO, AIME, RLVR, Tsinghua University"> <!-- TODO: add some keywords for search engine -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>交影数据管理 demo</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome_6_7_2.all.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome_6_7_2.all.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero hero-landing">
  <div class="hero-body">
    <div class="landing-shell">
      <div class="landing-card">
        <div class="hero-content">
          <div class="hero-column hero-left">
            <p class="landing-kicker">Joining AI</p>
            <h1 class="landing-title">Accelerate AI training from the origins with high quality data</h1>
            <p class="landing-summary">
              (Company summary)
            </p>
            <ul class="landing-bullets">
              <li>
                <span class="landing-bullet-icon">
                  <i class="fa-solid fa-chart-line"></i>
                </span>
                <div>
                  <strong>交影为啥牛逼1.</strong> 
                </div>
              </li>
              <li>
                <span class="landing-bullet-icon">
                  <i class="fa-solid fa-route"></i>
                </span>
                <div
                  <strong>交影为啥牛逼2.</strong> 
                </div>
              </li>
              <li>
                <span class="landing-bullet-icon">
                  <i class="fa-solid fa-layer-group"></i>
                </span>
                <div>
                  <strong>交影为啥牛逼3.</strong>
                </div>
              </li>
            </ul>
            <div class="landing-buttons">
              <a href="https://github.com/Joining-AI" class="landing-button">
                <span class="landing-button-icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </div>
          </div>
          <div class="hero-column hero-right">
            <div class="landing-image-frame video-frame">
              <video autoplay loop muted playsinline>
                <source src="./static/video/introvideo.mp4" type="video/mp4">
                <source src="./static/video/introvideo.webm" type="video/webm">
                Your browser does not support the video tag.
              </video>
            </div>
            <p class="landing-video-caption">
              公司介绍小视频
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section themed-section themed-promo">
  <div class="container is-max-desktop">
    <!-- Ad -->
    <div class="columns is-centered">
      <div class="column is-four-fifths section-card promo-card">
        <div class="content has-text-justified">
          <p class="section-text promo-banner">
            <i><a href="https://github.com/Joining-AI" class="author-name promo-link"><b>Joining AI</b></a> (Company Intro)
            </i>
          </p>  
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section themed-section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <h2 class="title is-3 section-title">Introducing our company</h2>
        <div class="content has-text-justified section-body">
          <p class="section-text">  
            Joining AI introduction
          </p>  
          <p class="section-text section-emphasis">  
          <i><b>有关交影的小问题</b></i>  
          </p>  
          <p class="section-text">  
          交影小问题的回答
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <video class="section-media" autoplay loop muted playsinline>
          <source src="./static/video/overviewvideo.mp4" type="video/mp4">
          <source src="./static/video/overviewvideo.webm" type="video/webm">
          Your browser does not support the video tag.
        </video>
        <!-- <h2 class="subtitle has-text-centered">
          <img src="./static/images/overview.png"/>
        </h2> -->
        <p class="section-footnote">
          Video: 交影小介绍视频
    </div>
  </div>
</section>


<section class="section themed-section themed-alt">
  <div class="container is-max-desktop">
    <!-- 交影数据平台 -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <h2 class="title is-3 section-title">Conclusion</h2>
        <div class="content has-text-justified section-body">
          <ol class="section-list">
            <li>
              <span class="section-insight-title"><b>“给平台起个拽名字”</b></span> <br>
              平台使用简易小指南。
            </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section themed-section themed-dark qa-section">
  <div class="container is-max-desktop">
    <!-- Q&A Section -->
    <div class="columns is-centered">
      <div class="column is-four-fifths section-card qa-card-group">
        <h2 class="title is-3 section-title has-text-centered qa-heading">
          <span class="icon-text">
            <span class="icon qa-heading-icon">
              <i class="fas fa-comments"></i>
            </span>
            <span>Q&A</span>
          </span>
        </h2>

        <!-- Q&A Item 1 -->
        <div class="qa-card">
          <div class="qa-question">
            <div class="q-marker">
              <span class="q-number">01</span>
              <span class="q-icon">Q</span>
            </div>
            <h3 class="question-text">
              学长学长，学长学长?
            </h3>
          </div>
          <div class="qa-answer">
            <div class="a-marker">
              <span class="a-icon">A</span>
            </div>
            <div class="answer-text">
              <p>
               学长好好给你回答一下
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section themed-section">
  <div class="container is-max-desktop">
    <!-- Fully Open-Source -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <h2 class="title is-3 section-title">Experiments</h2>
        <div class="content has-text-justified section-body">
          <p class="section-text">
            <span class="section-emphasis">We conducted experiments across <b>three representative domains</b> to evaluate the effect of RLVR on the reasoning ability boundaries of base and RLVR models.</span> <br>
          </p>
          <h3 class="title is-4 section-subtitle">Math</h3>
          <h1 class="subtitle has-text-centered">
            <img src="./static/images/Math.png" class="section-image section-image-wide"/>
          </h1>
          <p class="section-text">
            In the <b>math</b> experiments, we evaluate multiple LLM families (Qwen-2.5 and LLaMA-3.1) and their RL-trained variants on benchmarks like GSM8K, MATH500, and AIME24. 
            We analyze pass@<i>k</i> curves to compare base and RL-trained models, observing that RL improves low-<i>k</i> performance but reduces problem coverage at high <i>k</i>. 
            We manually inspect CoT validity to ensure correct answers stem from valid reasoning, not lucky guesses. 
            Additionally, we examine Oat-Zero-trained models and filter guessable problems to focus on challenging cases. 
            The results show base models maintain broader reasoning coverage despite RL's initial accuracy gains. 
          </p>
          <h3 class="title is-4 section-subtitle">Coding</h3>
          <h1 class="subtitle has-text-centered">
            <img src="./static/images/Coding.png" class="section-image section-image-medium"/>
          </h1>
          <p class="section-text">
            In the <b>coding</b> experiments, we evaluate the RLVR-trained model CodeR1-Zero-Qwen2.5-7B, derived from Qwen2.5-7B-Instruct-1M, on benchmarks like LiveCodeBench, HumanEval+, and MBPP+. 
            We assess performance using pass@<i>k</i> metrics, measuring correctness based on predefined test cases. 
            The results show RLVR improves single-sample pass@1 scores but reduces coverage at higher sampling counts (<i>k</i> = 128). 
            The original model exhibits continued potential for improvement with larger <i>k</i>, while RLVR's performance plateaus. 
            This indicates RLVR enhances deterministic accuracy but limits exploration diversity. 
          </p>
          <h3 class="title is-4 section-subtitle">Visual Reasoning</h3>
          <h1 class="subtitle has-text-centered">
            <img src="./static/images/qwenvl_7b_instruct_coverage_filter.png" class="section-image section-image-compact"/>
          </h1>
          <p class="section-text">
            In the experiments on <b>visual reasoning</b>, we evaluate Qwen-2.5-VL-7B on filtered visual reasoning benchmarks (MathVista and MathVision), removing multiple-choice questions to focus on robust problem-solving. 
            The improvements from RLVR in visual reasoning align with those seen in math and coding benchmarks, indicating that the original model already covers a broad range of solvable problems, even in multimodal tasks.
            The consistency across domains suggests that RLVR enhances reasoning capabilities without fundamentally altering the model's problem-solving approach.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section themed-section themed-alt">
  <div class="container is-max-desktop">
    <!-- Fully Open-Source -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <h2 class="title is-3 section-title">Case Study</h2>
        <div class="content has-text-justified section-body">
          <p class="section-text">
            We present <span class="section-emphasis"><I>ONE</I></span> of the sampled correct CoTs from the <span class="section-emphasis"><b>base</b></span> model, 
            manually selected from 2048 samplings for the hardest questions in AIME24. 
            The responses from the base model tend to be long CoTs and exhibit reflective behavior, 
            highlighting the strong reasoning ability inherent in the base model.
          </p>
          <h3 class="title is-4 section-subtitle">Example</h3>
          <h2 class="subtitle has-text-centered">
            <img src="./static/images/AIME24_16_Base_Answer.png" class="section-image section-image-full" />
          </h2>
          <p class="section-text">
            <a href="https://arxiv.org/abs/2505.16400" class="section-link section-text-large">AceReason-Nemotron</a> reported that after conducting 64 samples, their RL-trained model successfully solved four problems (No. <b>3</b>, <b>14</b>, <b>29</b>, and <b>30</b>) from the AIME24 dataset that DeepSeek-R1-Distill-Qwen-7B (base model in their RL training) failed to solve. While their RL-trained model is well-trained and impressively powerful, our findings suggest that the base model itself still exhibits considerable potential. With increased sampling, we observed that these four problems can indeed be solved by the base model: Problem No. <b>3</b> was solved after 5120 samples, and Problems No. <b>14</b>, <b>29</b>, and <b>30</b> were solved within 1024 samples. For each case, we provide representative examples of correct Chains of Thought (CoTs) and corresponding final answers:
          </p>
          <h2 class="subtitle has-text-centered section-embed">
            <iframe src="./Q4.html" width="100%" height="2950px" class="section-iframe"></iframe>
          </h2>
          <p class="section-footnote">
            Condensed: The process of consecutive reflective contents starting with "Wait," which are long and similar in the CoT, is summarized and abridged for better readability.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section themed-section">
  <div class="container is-max-desktop">
    <!-- Fully Open-Source -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths section-card">
        <h2 class="title is-3 section-title">BibTeX</h2>
        <div class="content has-text-justified section-body">
          <pre class="section-code"><code>@article{yue2025limit-of-rlvr,
  title={Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?},
  author={Yue, Yang and Chen, Zhiqi and Lu, Rui and Zhao, Andrew and Wang, Zhaokai and Yue, Yang and Song, Shiji and Huang, Gao},
  journal={arXiv preprint arXiv:2504.13837},
  year={2025}
}</code></pre>
        </div>
      </div>
    </div>
  </div>
</section>


</body>
</html>
